{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_introduction.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzw2csoD_MVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imE1NNtCP3Nu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "55b8ec31-1812-4e34-d455-fcbfa54648d1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torchvision import datasets, transforms\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import keras \n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfH_MR0HRks1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  ## constructor\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28, 50)  ## linear model\n",
        "    self.fc1_drop = nn.Dropout(0.2)  ## dropout column 20  %\n",
        "    self.fc2 = nn.Linear(50, 50)     ## linear previous and after 50,50\n",
        "    self.fc2_drop = nn.Dropout(0.2)\n",
        "    self.fc3 = nn.Linear(50, 10)     ## final layer\n",
        "    \n",
        "    ## this is the layer information\n",
        "    \n",
        "  def forward(self,x):\n",
        "    # adding functionality\n",
        "    x = x.view(-1,28*28)\n",
        "    ## adding the rectified linear to the layer 1\n",
        "    x=F.relu(self.fc1(x))  ## ading the value to x to the layer and then apply relu\n",
        "    x=self.fc1_drop(x)\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x =self.fc2_drop(x)\n",
        "    return F.log_softmax(self.fc3(x),dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcXupYDrUTGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "734b32ed-c756-4744-9b2f-8cd92bb35caf"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.1.0  Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4pU4RrnUXyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLd3eivuUhiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c192b86a-7e78-444a-e656-1b9feb17bb65"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.1.0  Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw2YbiKeVBEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', \n",
        "                               train=True, \n",
        "                               download=True, \n",
        "                               transform=transforms.ToTensor())\n",
        "\n",
        "validation_dataset = datasets.MNIST('./data', \n",
        "                                    train=False, \n",
        "                                    transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
        "                                                batch_size=batch_size, \n",
        "                                                shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qihxZ-s0VtI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9cdd98f5-b40d-4de6-ca23-a6d014ccde7b"
      },
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
            "y_train: torch.Size([32]) type: torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr0SXuXEVvkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "68fa133a-981c-4dd8-ca18-0a6a61bf48b4"
      },
      "source": [
        "pltsize=1\n",
        "plt.figure(figsize=(10*pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1,10,i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray\")\n",
        "    plt.title('Class: '+str(y_train[i].item()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAABhCAYAAAAURe8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnVgppZRSStlEJ1ZKKaWUUjb5fzGT2fCyiGUwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6mS9D0HVzEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, log_interval=200):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Loop over each batch from the training set\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Copy data to GPU if needed\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Zero gradient buffers\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        # Pass data through the network\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk_dNaOXV5Gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(loss_vector, accuracy_vector):\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    for data, target in validation_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        val_loss += criterion(output, target).data.item()\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    val_loss /= len(validation_loader)\n",
        "    loss_vector.append(val_loss)\n",
        "\n",
        "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
        "    accuracy_vector.append(accuracy)\n",
        "    \n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        val_loss, correct, len(validation_loader.dataset), accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbP81sJVV7vI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1225
        },
        "outputId": "a046b198-4839-44de-f733-7ab236c78d77"
      },
      "source": [
        "%%time\n",
        "epochs = 5\n",
        "\n",
        "lossv, accv = [], []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.326291\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.095009\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.380959\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.881740\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.690922\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.582633\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.530609\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.463946\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.466501\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.456487\n",
            "\n",
            "Validation set: Average loss: 0.3620, Accuracy: 9002/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.808021\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.621670\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.275245\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.368286\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.484802\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.615639\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.247310\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.716126\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.360720\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.308680\n",
            "\n",
            "Validation set: Average loss: 0.2638, Accuracy: 9208/10000 (92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.317980\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.201986\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.318392\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.359029\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.303665\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.458019\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.339768\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.239817\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.486745\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.129122\n",
            "\n",
            "Validation set: Average loss: 0.2100, Accuracy: 9385/10000 (94%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.226425\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.679847\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.144922\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.756314\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.426569\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.134836\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.178588\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.979327\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.143711\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.075930\n",
            "\n",
            "Validation set: Average loss: 0.1801, Accuracy: 9480/10000 (95%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.393515\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.340010\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.504402\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.226580\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.196558\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.303004\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.112435\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.101312\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.348445\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.200332\n",
            "\n",
            "Validation set: Average loss: 0.1610, Accuracy: 9510/10000 (95%)\n",
            "\n",
            "CPU times: user 40.2 s, sys: 1.04 s, total: 41.2 s\n",
            "Wall time: 41.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4481-0F_V-DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}